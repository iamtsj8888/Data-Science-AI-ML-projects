{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "otIfloe19hB8",
        "pKNc6Swv9nqZ"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Load Spacy"
      ],
      "metadata": {
        "id": "otIfloe19hB8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zhjcXDJM80R5",
        "outputId": "7239e35a-ebef-4088-df11-1b5047271bdb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;3m⚠ As of spaCy v3.0, shortcuts like 'de' are deprecated. Please use the\n",
            "full pipeline package name 'de_core_news_sm' instead.\u001b[0m\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting de-core-news-sm==3.4.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-3.4.0/de_core_news_sm-3.4.0-py3-none-any.whl (14.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 14.6 MB 29.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<3.5.0,>=3.4.0 in /usr/local/lib/python3.8/dist-packages (from de-core-news-sm==3.4.0) (3.4.3)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (1.0.3)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (0.9.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (1.0.9)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (0.7.0)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2.4.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2.11.3)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (8.1.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2.23.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (1.10.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (57.4.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2.0.7)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (1.21.6)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (3.0.10)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (3.0.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2.0.8)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (4.64.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (3.3.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (0.10.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (3.0.9)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.8/dist-packages (from pathy>=0.3.5->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (5.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.8/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (4.1.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (1.24.3)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (0.0.3)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (0.7.9)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.8/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2.0.1)\n",
            "Installing collected packages: de-core-news-sm\n",
            "Successfully installed de-core-news-sm-3.4.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('de_core_news_sm')\n",
            "\u001b[38;5;3m⚠ As of spaCy v3.0, shortcuts like 'en' are deprecated. Please use the\n",
            "full pipeline package name 'en_core_web_sm' instead.\u001b[0m\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting en-core-web-sm==3.4.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.4.1/en_core_web_sm-3.4.1-py3-none-any.whl (12.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.8 MB 29.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<3.5.0,>=3.4.0 in /usr/local/lib/python3.8/dist-packages (from en-core-web-sm==3.4.1) (3.4.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (21.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.4.5)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (8.1.5)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.3.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.10.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.0.9)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.7.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.11.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (4.64.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.0.7)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.0.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.0.8)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (57.4.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.23.0)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.9.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.10.2)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.0.8)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.0.10)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.21.6)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.0.9)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.8/dist-packages (from pathy>=0.3.5->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (5.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.8/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (4.1.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.24.3)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.0.3)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.7.9)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.8/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.0.1)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n"
          ]
        }
      ],
      "source": [
        "! python -m spacy download de\n",
        "! python -m spacy download en"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install Torch, TorchText, TorchData"
      ],
      "metadata": {
        "id": "pKNc6Swv9nqZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip3 install torch torchdata torchtext"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "H--g7Qf7-SY7",
        "outputId": "7f352154-c2a8-4107-890f-71dec1ee5477"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (1.12.1+cu113)\n",
            "Collecting torchdata\n",
            "  Downloading torchdata-0.5.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.5 MB 13.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torchtext in /usr/local/lib/python3.8/dist-packages (0.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch) (4.1.1)\n",
            "Collecting torch\n",
            "  Downloading torch-1.13.0-cp38-cp38-manylinux1_x86_64.whl (890.2 MB)\n",
            "\u001b[K     |██████████████████████████████  | 834.1 MB 1.3 MB/s eta 0:00:45tcmalloc: large alloc 1147494400 bytes == 0x666f8000 @  0x7f289c23a615 0x5d631c 0x51e4f1 0x51e67b 0x4f7585 0x49ca7c 0x4fdff5 0x49caa1 0x4fdff5 0x49ced5 0x4f60a9 0x55f926 0x4f60a9 0x55f926 0x4f60a9 0x55f926 0x5d7c18 0x5d9412 0x586636 0x5d813c 0x55f3fd 0x55e571 0x5d7cf1 0x49ced5 0x55e571 0x5d7cf1 0x49ec69 0x5d7c18 0x49ca7c 0x4fdff5 0x49ced5\n",
            "\u001b[K     |████████████████████████████████| 890.2 MB 5.9 kB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchdata) (2.23.0)\n",
            "Collecting portalocker>=2.0.0\n",
            "  Downloading portalocker-2.6.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting urllib3>=1.25\n",
            "  Downloading urllib3-1.26.13-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[K     |████████████████████████████████| 140 kB 73.9 MB/s \n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[K     |████████████████████████████████| 849 kB 60.6 MB/s \n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 317.1 MB 33 kB/s \n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 557.1 MB 11 kB/s \n",
            "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu11==11.7.99\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 21.0 MB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel in /usr/local/lib/python3.8/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.38.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (57.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchtext) (1.21.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from torchtext) (4.64.1)\n",
            "Collecting torchtext\n",
            "  Downloading torchtext-0.14.0-cp38-cp38-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0 MB 61.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchdata) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchdata) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchdata) (2.10)\n",
            "Collecting urllib3>=1.25\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 79.9 MB/s \n",
            "\u001b[?25hInstalling collected packages: nvidia-cublas-cu11, urllib3, nvidia-cudnn-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, torch, portalocker, torchtext, torchdata\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.12.1+cu113\n",
            "    Uninstalling torch-1.12.1+cu113:\n",
            "      Successfully uninstalled torch-1.12.1+cu113\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.13.1\n",
            "    Uninstalling torchtext-0.13.1:\n",
            "      Successfully uninstalled torchtext-0.13.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.13.1+cu113 requires torch==1.12.1, but you have torch 1.13.0 which is incompatible.\n",
            "torchaudio 0.12.1+cu113 requires torch==1.12.1, but you have torch 1.13.0 which is incompatible.\u001b[0m\n",
            "Successfully installed nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 portalocker-2.6.0 torch-1.13.0 torchdata-0.5.0 torchtext-0.14.0 urllib3-1.25.11\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torch",
                  "torchtext",
                  "urllib3"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install torchtext==0.9"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r8xQEU7HB9_c",
        "outputId": "fcbeaf42-ce4e-44cd-fc76-84263b493347"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchtext==0.9\n",
            "  Downloading torchtext-0.9.0-cp38-cp38-manylinux1_x86_64.whl (7.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.0 MB 21.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchtext==0.9) (1.21.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from torchtext==0.9) (4.64.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchtext==0.9) (2.23.0)\n",
            "Collecting torch==1.8.0\n",
            "  Downloading torch-1.8.0-cp38-cp38-manylinux1_x86_64.whl (735.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 735.5 MB 17 kB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch==1.8.0->torchtext==0.9) (4.1.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext==0.9) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext==0.9) (1.25.11)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext==0.9) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext==0.9) (3.0.4)\n",
            "Installing collected packages: torch, torchtext\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.13.0\n",
            "    Uninstalling torch-1.13.0:\n",
            "      Successfully uninstalled torch-1.13.0\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.14.0\n",
            "    Uninstalling torchtext-0.14.0:\n",
            "      Successfully uninstalled torchtext-0.14.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.13.1+cu113 requires torch==1.12.1, but you have torch 1.8.0 which is incompatible.\n",
            "torchdata 0.5.0 requires torch==1.13.0, but you have torch 1.8.0 which is incompatible.\n",
            "torchaudio 0.12.1+cu113 requires torch==1.12.1, but you have torch 1.8.0 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.8.0 torchtext-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install torch==1.8.0+cu111 torchvision==0.9.0+cu111 torchaudio==0.8.0 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        },
        "id": "ks1zB_SuQLI8",
        "outputId": "851adf55-23b1-4a47-b0e7-6cf2e5d6a6a5"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.8.0+cu111\n",
            "  Downloading https://download.pytorch.org/whl/cu111/torch-1.8.0%2Bcu111-cp38-cp38-linux_x86_64.whl (1982.2 MB)\n",
            "\u001b[K     |█████████████▌                  | 834.1 MB 1.3 MB/s eta 0:14:24tcmalloc: large alloc 1147494400 bytes == 0x393e2000 @  0x7f4351c34615 0x5d631c 0x51e4f1 0x51e67b 0x4f7585 0x49ca7c 0x4fdff5 0x49caa1 0x4fdff5 0x49ced5 0x4f60a9 0x55f926 0x4f60a9 0x55f926 0x4f60a9 0x55f926 0x5d7c18 0x5d9412 0x586636 0x5d813c 0x55f3fd 0x55e571 0x5d7cf1 0x49ced5 0x55e571 0x5d7cf1 0x49ec69 0x5d7c18 0x49ca7c 0x4fdff5 0x49ced5\n",
            "\u001b[K     |█████████████████               | 1055.7 MB 1.2 MB/s eta 0:12:29tcmalloc: large alloc 1434370048 bytes == 0x7da38000 @  0x7f4351c34615 0x5d631c 0x51e4f1 0x51e67b 0x4f7585 0x49ca7c 0x4fdff5 0x49caa1 0x4fdff5 0x49ced5 0x4f60a9 0x55f926 0x4f60a9 0x55f926 0x4f60a9 0x55f926 0x5d7c18 0x5d9412 0x586636 0x5d813c 0x55f3fd 0x55e571 0x5d7cf1 0x49ced5 0x55e571 0x5d7cf1 0x49ec69 0x5d7c18 0x49ca7c 0x4fdff5 0x49ced5\n",
            "\u001b[K     |█████████████████████▋          | 1336.2 MB 1.3 MB/s eta 0:08:28tcmalloc: large alloc 1792966656 bytes == 0x286a000 @  0x7f4351c34615 0x5d631c 0x51e4f1 0x51e67b 0x4f7585 0x49ca7c 0x4fdff5 0x49caa1 0x4fdff5 0x49ced5 0x4f60a9 0x55f926 0x4f60a9 0x55f926 0x4f60a9 0x55f926 0x5d7c18 0x5d9412 0x586636 0x5d813c 0x55f3fd 0x55e571 0x5d7cf1 0x49ced5 0x55e571 0x5d7cf1 0x49ec69 0x5d7c18 0x49ca7c 0x4fdff5 0x49ced5\n",
            "\u001b[K     |███████████████████████████▎    | 1691.1 MB 1.7 MB/s eta 0:02:50tcmalloc: large alloc 2241208320 bytes == 0x6d652000 @  0x7f4351c34615 0x5d631c 0x51e4f1 0x51e67b 0x4f7585 0x49ca7c 0x4fdff5 0x49caa1 0x4fdff5 0x49ced5 0x4f60a9 0x55f926 0x4f60a9 0x55f926 0x4f60a9 0x55f926 0x5d7c18 0x5d9412 0x586636 0x5d813c 0x55f3fd 0x55e571 0x5d7cf1 0x49ced5 0x55e571 0x5d7cf1 0x49ec69 0x5d7c18 0x49ca7c 0x4fdff5 0x49ced5\n",
            "\u001b[K     |████████████████████████████████| 1982.2 MB 1.2 MB/s eta 0:00:01tcmalloc: large alloc 1982242816 bytes == 0xf2fb4000 @  0x7f4351c331e7 0x4d3280 0x4d330c 0x5d631c 0x51e4f1 0x51e67b 0x4f7585 0x49ca7c 0x55e571 0x5d7cf1 0x49ca7c 0x55e571 0x5d7cf1 0x49ca7c 0x55e571 0x5d7cf1 0x49ca7c 0x55e571 0x5d7cf1 0x49ca7c 0x55e571 0x5d7cf1 0x49ca7c 0x5d7c18 0x49ca7c 0x55e571 0x5d7cf1 0x49ced5 0x4fdff5 0x49ced5 0x55e571\n",
            "tcmalloc: large alloc 2477809664 bytes == 0x1dd6b6000 @  0x7f4351c34615 0x5d631c 0x51e4f1 0x51e67b 0x4f7585 0x49ca7c 0x55e571 0x5d7cf1 0x49ca7c 0x55e571 0x5d7cf1 0x49ca7c 0x55e571 0x5d7cf1 0x49ca7c 0x55e571 0x5d7cf1 0x49ca7c 0x55e571 0x5d7cf1 0x49ca7c 0x5d7c18 0x49ca7c 0x55e571 0x5d7cf1 0x49ced5 0x4fdff5 0x49ced5 0x55e571 0x5d7cf1 0x4fea58\n",
            "\u001b[K     |████████████████████████████████| 1982.2 MB 5.5 kB/s \n",
            "\u001b[?25hCollecting torchvision==0.9.0+cu111\n",
            "  Downloading https://download.pytorch.org/whl/cu111/torchvision-0.9.0%2Bcu111-cp38-cp38-linux_x86_64.whl (17.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 17.6 MB 818 kB/s \n",
            "\u001b[?25hCollecting torchaudio==0.8.0\n",
            "  Downloading torchaudio-0.8.0-cp38-cp38-manylinux1_x86_64.whl (1.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 32.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torch==1.8.0+cu111) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch==1.8.0+cu111) (4.1.1)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.8/dist-packages (from torchvision==0.9.0+cu111) (7.1.2)\n",
            "Installing collected packages: torch, torchvision, torchaudio\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.8.0\n",
            "    Uninstalling torch-1.8.0:\n",
            "      Successfully uninstalled torch-1.8.0\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.13.1+cu113\n",
            "    Uninstalling torchvision-0.13.1+cu113:\n",
            "      Successfully uninstalled torchvision-0.13.1+cu113\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 0.12.1+cu113\n",
            "    Uninstalling torchaudio-0.12.1+cu113:\n",
            "      Successfully uninstalled torchaudio-0.12.1+cu113\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchdata 0.5.0 requires torch==1.13.0, but you have torch 1.8.0+cu111 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.8.0+cu111 torchaudio-0.8.0 torchvision-0.9.0+cu111\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torch"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Verify Versions"
      ],
      "metadata": {
        "id": "Fd3WcVLi_oYd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oEQWO2uE9lbW",
        "outputId": "4620b52d-abd8-4a45-84b5-164ae23cf5c5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.8.0+cu111\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchtext\n",
        "print(torchtext.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UclGaMDnFV3I",
        "outputId": "759cb326-84c1-4c1d-cb2e-478089bfafb2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Libraries"
      ],
      "metadata": {
        "id": "TFHdhYYrNzVp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import spacy\n",
        "from torchtext.data.metrics import bleu_score\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "# from utils import translate_sentence, bleu, save_checkpoint, load_checkpoint\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torchtext.legacy.datasets import Multi30k\n",
        "from torchtext.legacy.data import Field, BucketIterator"
      ],
      "metadata": {
        "id": "BCUeYtqV9LlW"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build Dataloader/Vocab"
      ],
      "metadata": {
        "id": "xcP4tJCAOJSv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spacy_ger = spacy.load('de_core_news_sm')\n",
        "spacy_eng = spacy.load('en_core_web_sm')"
      ],
      "metadata": {
        "id": "rGo_N29w_0O9"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_ger(text):\n",
        "    return [tok.text for tok in spacy_ger.tokenizer(text)]\n",
        "\n",
        "def tokenize_eng(text):\n",
        "    return [tok.text for tok in spacy_eng.tokenizer(text)]"
      ],
      "metadata": {
        "id": "7MOQL942AMmA"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "german = Field(tokenize=tokenize_ger, lower=True, init_token=\"<sos>\", eos_token=\"<eos>\")\n",
        "english = Field(tokenize=tokenize_eng, lower=True, init_token=\"<sos>\", eos_token=\"<eos>\")"
      ],
      "metadata": {
        "id": "apxXWmhHFfqp"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, valid_data, test_data = Multi30k.splits(\n",
        "    exts=(\".de\", \".en\"), fields=(german, english)\n",
        ")"
      ],
      "metadata": {
        "id": "4sUriCvPFipi"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "german.build_vocab(train_data, max_size=10000, min_freq=2)\n",
        "english.build_vocab(train_data, max_size=10000, min_freq=2)"
      ],
      "metadata": {
        "id": "19vqDWV6FtQK"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Transformer"
      ],
      "metadata": {
        "id": "b_ibwuHDOTUz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Transformer(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        embedding_size,\n",
        "        src_vocab_size,\n",
        "        trg_vocab_size,\n",
        "        src_pad_idx,\n",
        "        num_heads,\n",
        "        num_encoder_layers,\n",
        "        num_decoder_layers,\n",
        "        forward_expansion,\n",
        "        dropout,\n",
        "        max_len,\n",
        "        device,\n",
        "    ):\n",
        "        super(Transformer, self).__init__()\n",
        "        self.src_word_embedding = nn.Embedding(src_vocab_size, embedding_size)\n",
        "        self.src_position_embedding = nn.Embedding(max_len, embedding_size)\n",
        "        self.trg_word_embedding = nn.Embedding(trg_vocab_size, embedding_size)\n",
        "        self.trg_position_embedding = nn.Embedding(max_len, embedding_size)\n",
        "\n",
        "        self.device = device\n",
        "        self.transformer = nn.Transformer(\n",
        "            embedding_size,\n",
        "            num_heads,\n",
        "            num_encoder_layers,\n",
        "            num_decoder_layers,\n",
        "            forward_expansion,\n",
        "            dropout,\n",
        "        )\n",
        "        self.fc_out = nn.Linear(embedding_size, trg_vocab_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.src_pad_idx = src_pad_idx\n",
        "\n",
        "    def make_src_mask(self, src):\n",
        "        src_mask = src.transpose(0, 1) == self.src_pad_idx\n",
        "\n",
        "        # (N, src_len)\n",
        "        return src_mask.to(self.device)\n",
        "\n",
        "    def forward(self, src, trg):\n",
        "        src_seq_length, N = src.shape\n",
        "        trg_seq_length, N = trg.shape\n",
        "\n",
        "        src_positions = (\n",
        "            torch.arange(0, src_seq_length)\n",
        "            .unsqueeze(1)\n",
        "            .expand(src_seq_length, N)\n",
        "            .to(self.device)\n",
        "        )\n",
        "\n",
        "        trg_positions = (\n",
        "            torch.arange(0, trg_seq_length)\n",
        "            .unsqueeze(1)\n",
        "            .expand(trg_seq_length, N)\n",
        "            .to(self.device)\n",
        "        )\n",
        "\n",
        "        embed_src = self.dropout(\n",
        "            (self.src_word_embedding(src) + self.src_position_embedding(src_positions))\n",
        "        )\n",
        "        embed_trg = self.dropout(\n",
        "            (self.trg_word_embedding(trg) + self.trg_position_embedding(trg_positions))\n",
        "        )\n",
        "\n",
        "        src_padding_mask = self.make_src_mask(src)\n",
        "        trg_mask = self.transformer.generate_square_subsequent_mask(trg_seq_length).to(\n",
        "            self.device\n",
        "        )\n",
        "\n",
        "        out = self.transformer(\n",
        "            embed_src,\n",
        "            embed_trg,\n",
        "            src_key_padding_mask=src_padding_mask,\n",
        "            tgt_mask=trg_mask,\n",
        "        )\n",
        "        out = self.fc_out(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "lMd4wVQ5F-I6"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set Device (CPU/GPU)"
      ],
      "metadata": {
        "id": "8hd9Fj0hOb8R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "1NqxZF-wGD1T"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyperparams"
      ],
      "metadata": {
        "id": "5W1LP5YNOj9_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "load_model = False\n",
        "save_model = True\n",
        "\n",
        "# Training hyperparameters\n",
        "num_epochs = 50\n",
        "learning_rate = 3e-4\n",
        "batch_size = 32\n",
        "\n",
        "# Model hyperparameters\n",
        "src_vocab_size = len(german.vocab)\n",
        "trg_vocab_size = len(english.vocab)\n",
        "embedding_size = 512\n",
        "num_heads = 8\n",
        "num_encoder_layers = 3\n",
        "num_decoder_layers = 3\n",
        "dropout = 0.10\n",
        "max_len = 100\n",
        "forward_expansion = 4\n",
        "src_pad_idx = english.vocab.stoi[\"<pad>\"]"
      ],
      "metadata": {
        "id": "LQPkzsEzGKsS"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "writer = SummaryWriter(\"runs/loss_plot\")\n",
        "step = 0"
      ],
      "metadata": {
        "id": "JZ8m83nFGgSS"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Data Iterator/Loader"
      ],
      "metadata": {
        "id": "WN_GCS-pOro-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data),\n",
        "    batch_size=batch_size,\n",
        "    sort_within_batch=True,\n",
        "    sort_key=lambda x: len(x.src),\n",
        "    device=device,\n",
        ")"
      ],
      "metadata": {
        "id": "waCgR8suGj8K"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Init Model"
      ],
      "metadata": {
        "id": "AHL6TfQWO0-c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Transformer(\n",
        "    embedding_size,\n",
        "    src_vocab_size,\n",
        "    trg_vocab_size,\n",
        "    src_pad_idx,\n",
        "    num_heads,\n",
        "    num_encoder_layers,\n",
        "    num_decoder_layers,\n",
        "    forward_expansion,\n",
        "    dropout,\n",
        "    max_len,\n",
        "    device,\n",
        ").to(device)"
      ],
      "metadata": {
        "id": "YCvq1qQhHvDh"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer, factor=0.1, patience=10, verbose=True\n",
        ")"
      ],
      "metadata": {
        "id": "qjbXpErFGmNy"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pad_idx = english.vocab.stoi[\"<pad>\"]\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)"
      ],
      "metadata": {
        "id": "K59Z8_tuHpja"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utils"
      ],
      "metadata": {
        "id": "HOTgDuJZIJKU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def translate_sentence(model, sentence, german, english, device, max_length=50):\n",
        "    # Load german tokenizer\n",
        "    spacy_ger = spacy.load(\"de_core_news_sm\")\n",
        "\n",
        "    # Create tokens using spacy and everything in lower case (which is what our vocab is)\n",
        "    if type(sentence) == str:\n",
        "        tokens = [token.text.lower() for token in spacy_ger(sentence)]\n",
        "    else:\n",
        "        tokens = [token.lower() for token in sentence]\n",
        "\n",
        "    # Add <SOS> and <EOS> in beginning and end respectively\n",
        "    tokens.insert(0, german.init_token)\n",
        "    tokens.append(german.eos_token)\n",
        "\n",
        "    # Go through each german token and convert to an index\n",
        "    text_to_indices = [german.vocab.stoi[token] for token in tokens]\n",
        "\n",
        "    # Convert to Tensor\n",
        "    sentence_tensor = torch.LongTensor(text_to_indices).unsqueeze(1).to(device)\n",
        "\n",
        "    outputs = [english.vocab.stoi[\"<sos>\"]]\n",
        "    for i in range(max_length):\n",
        "        trg_tensor = torch.LongTensor(outputs).unsqueeze(1).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output = model(sentence_tensor, trg_tensor)\n",
        "\n",
        "        best_guess = output.argmax(2)[-1, :].item()\n",
        "        outputs.append(best_guess)\n",
        "\n",
        "        if best_guess == english.vocab.stoi[\"<eos>\"]:\n",
        "            break\n",
        "\n",
        "    translated_sentence = [english.vocab.itos[idx] for idx in outputs]\n",
        "    # remove start token\n",
        "    return translated_sentence[1:]\n",
        "\n",
        "\n",
        "def bleu(data, model, german, english, device):\n",
        "    targets = []\n",
        "    outputs = []\n",
        "\n",
        "    for example in data:\n",
        "        src = vars(example)[\"src\"]\n",
        "        trg = vars(example)[\"trg\"]\n",
        "\n",
        "        prediction = translate_sentence(model, src, german, english, device)\n",
        "        prediction = prediction[:-1]  # remove <eos> token\n",
        "\n",
        "        targets.append([trg])\n",
        "        outputs.append(prediction)\n",
        "\n",
        "    return bleu_score(outputs, targets)\n",
        "\n",
        "\n",
        "def save_checkpoint(state, filename=\"my_checkpoint.pth.tar\"):\n",
        "    print(\"=> Saving checkpoint\")\n",
        "    torch.save(state, filename)\n",
        "\n",
        "\n",
        "def load_checkpoint(checkpoint, model, optimizer):\n",
        "    print(\"=> Loading checkpoint\")\n",
        "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
        "    optimizer.load_state_dict(checkpoint[\"optimizer\"])"
      ],
      "metadata": {
        "id": "xV0nmn7AII07"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Model"
      ],
      "metadata": {
        "id": "Yenkz2UCIM3y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if load_model:\n",
        "    load_checkpoint(torch.load(\"colab-50ep.pth\"), model, optimizer)\n",
        "\n",
        "sentence = \"ein pferd geht unter einer brücke neben einem boot.\""
      ],
      "metadata": {
        "id": "eh_7cfmsH1yi"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "    print(f\"[Epoch {epoch} / {num_epochs}]\")\n",
        "\n",
        "    if save_model:\n",
        "        checkpoint = {\n",
        "            \"state_dict\": model.state_dict(),\n",
        "            \"optimizer\": optimizer.state_dict(),\n",
        "        }\n",
        "        save_checkpoint(checkpoint, \"colab-50ep.pth\")\n",
        "\n",
        "    model.eval()\n",
        "    translated_sentence = translate_sentence(\n",
        "        model, sentence, german, english, device, max_length=50\n",
        "    )\n",
        "\n",
        "    print(f\"Translated example sentence: \\n {translated_sentence}\")\n",
        "    model.train()\n",
        "    losses = []\n",
        "\n",
        "    for batch_idx, batch in enumerate(train_iterator):\n",
        "        # Get input and targets and get to cuda\n",
        "        inp_data = batch.src.to(device)\n",
        "        target = batch.trg.to(device)\n",
        "\n",
        "        # Forward prop\n",
        "        output = model(inp_data, target[:-1, :])\n",
        "\n",
        "        # Output is of shape (trg_len, batch_size, output_dim) but Cross Entropy Loss\n",
        "        # doesn't take input in that form. For example if we have MNIST we want to have\n",
        "        # output to be: (N, 10) and targets just (N). Here we can view it in a similar\n",
        "        # way that we have output_words * batch_size that we want to send in into\n",
        "        # our cost function, so we need to do some reshapin.\n",
        "        # Let's also remove the start token while we're at it\n",
        "        output = output.reshape(-1, output.shape[2])\n",
        "        target = target[1:].reshape(-1)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        loss = criterion(output, target)\n",
        "        losses.append(loss.item())\n",
        "\n",
        "        # Back prop\n",
        "        loss.backward()\n",
        "        # Clip to avoid exploding gradient issues, makes sure grads are\n",
        "        # within a healthy range\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
        "\n",
        "        # Gradient descent step\n",
        "        optimizer.step()\n",
        "\n",
        "        # plot to tensorboard\n",
        "        writer.add_scalar(\"Training loss\", loss, global_step=step)\n",
        "        step += 1\n",
        "\n",
        "    mean_loss = sum(losses) / len(losses)\n",
        "    scheduler.step(mean_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qR2y1ebEIPn6",
        "outputId": "3c4b2a22-f5ac-44bf-dede-a2adf1614b52"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 0 / 50]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['watermelon', 'mosque', 'watermelon', 'bandanna', 'walking', 'blue', 'watermelon', 'watermelon', 'branches', 'walking', 'talent', 'scrubbing', 'watermelon', 'scrubbing', 'walking', 'talent', 'walking', 'talent', '&', 'necktie', 'homeless', 'walking', 'watermelon', 'loom', 'patrick', 'yells', 'waterside', 'homeless', 'walking', '&', 'troop', '&', 'features', 'walking', 'talent', 'scrubbing', 'talent', 'walking', 'denim', 'nibbling', 'branches', 'entertainer', 'entertainer', 'talent', 'walking', '&', 'showing', 'temporary', 'branches', 'walking']\n",
            "[Epoch 1 / 50]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['a', 'horse', 'walks', 'under', 'a', 'bridge', 'next', 'to', 'a', 'boat', '.', '<eos>']\n",
            "[Epoch 2 / 50]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['a', 'horse', 'is', 'walking', 'under', 'a', 'bridge', 'next', 'to', 'a', 'boat', '.', '<eos>']\n",
            "[Epoch 3 / 50]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['a', 'horse', 'walks', 'under', 'a', 'bridge', 'next', 'to', 'a', 'boat', '.', '<eos>']\n",
            "[Epoch 4 / 50]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['a', 'horse', 'is', 'walking', 'under', 'a', 'bridge', 'next', 'to', 'a', 'boat', '.', '<eos>']\n",
            "[Epoch 5 / 50]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['a', 'horse', 'is', 'walking', 'under', 'a', 'bridge', 'next', 'to', 'a', 'boat', '.', '<eos>']\n",
            "[Epoch 6 / 50]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['a', 'horse', 'is', 'walking', 'under', 'a', 'bridge', 'next', 'to', 'a', 'boat', '.', '<eos>']\n",
            "[Epoch 7 / 50]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['a', 'horse', 'is', 'walking', 'under', 'a', 'bridge', 'next', 'to', 'a', 'boat', '.', '<eos>']\n",
            "[Epoch 8 / 50]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['a', 'horse', 'walks', 'under', 'a', 'boat', 'next', 'to', 'a', 'boat', '.', '<eos>']\n",
            "[Epoch 9 / 50]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['a', 'horse', 'walks', 'under', 'a', 'bridge', 'next', 'to', 'a', 'bridge', '.', '<eos>']\n",
            "[Epoch 10 / 50]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['a', 'horse', 'walks', 'under', 'a', 'bridge', 'next', 'to', 'a', 'bridge', '.', '<eos>']\n",
            "[Epoch 11 / 50]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['a', 'horse', 'is', 'walking', 'by', 'a', 'boat', 'under', 'a', 'bridge', '.', '<eos>']\n",
            "[Epoch 12 / 50]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['a', 'horse', 'is', 'walking', 'beside', 'a', 'bridge', 'under', 'a', 'bridge', '.', '<eos>']\n",
            "[Epoch 13 / 50]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['a', 'horse', 'walks', 'under', 'a', 'bridge', 'near', 'a', 'boat', '.', '<eos>']\n",
            "[Epoch 14 / 50]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['a', 'horse', 'walks', 'under', 'a', 'bridge', 'next', 'to', 'a', 'boat', '.', '<eos>']\n",
            "[Epoch 15 / 50]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['a', 'horse', 'is', 'walking', 'beside', 'a', 'boat', '.', '<eos>']\n",
            "[Epoch 16 / 50]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['a', 'horse', 'walks', 'underneath', 'a', 'bridge', 'next', 'to', 'a', 'boat', '.', '<eos>']\n",
            "[Epoch 17 / 50]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['a', 'horse', 'walks', 'underneath', 'a', 'bridge', 'next', 'to', 'a', 'boat', '.', '<eos>']\n",
            "[Epoch 18 / 50]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['a', 'horse', 'walks', 'under', 'a', 'bridge', 'next', 'to', 'a', 'boat', '.', '<eos>']\n",
            "[Epoch 19 / 50]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['a', 'horse', 'walks', 'beside', 'a', 'boat', 'under', 'a', 'bridge', '.', '<eos>']\n",
            "[Epoch 20 / 50]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['a', 'horse', 'is', 'walking', 'underneath', 'a', 'bridge', 'under', 'a', 'bridge', '.', '<eos>']\n",
            "[Epoch 21 / 50]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['a', 'horse', 'is', 'walking', 'beside', 'a', 'boat', 'under', 'a', 'bridge', '.', '<eos>']\n",
            "[Epoch 22 / 50]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['a', 'horse', 'is', 'walking', 'under', 'a', 'bridge', 'next', 'to', 'a', 'boat', '.', '<eos>']\n",
            "[Epoch 23 / 50]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['a', 'horse', 'is', 'walking', 'beside', 'a', 'boat', 'under', 'a', 'bridge', '.', '<eos>']\n",
            "[Epoch 24 / 50]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['a', 'horse', 'is', 'walking', 'beside', 'a', 'boat', 'under', 'a', 'bridge', '.', '<eos>']\n",
            "[Epoch 25 / 50]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['a', 'horse', 'is', 'walking', 'beside', 'a', 'boat', 'under', 'a', 'bridge', '.', '<eos>']\n",
            "[Epoch 26 / 50]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['a', 'horse', 'is', 'walking', 'beside', 'a', 'boat', 'under', 'a', 'bridge', '.', '<eos>']\n",
            "[Epoch 27 / 50]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['a', 'horse', 'is', 'walking', 'beside', 'a', 'boat', 'under', 'a', 'bridge', '.', '<eos>']\n",
            "[Epoch 28 / 50]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['a', 'horse', 'is', 'walking', 'beside', 'a', 'boat', 'under', 'a', 'bridge', '.', '<eos>']\n",
            "[Epoch 29 / 50]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['a', 'horse', 'is', 'walking', 'beside', 'a', 'boat', 'under', 'a', 'bridge', '.', '<eos>']\n",
            "[Epoch 30 / 50]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['a', 'horse', 'is', 'walking', 'beside', 'a', 'boat', 'under', 'a', 'bridge', '.', '<eos>']\n",
            "[Epoch 31 / 50]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['a', 'horse', 'is', 'walking', 'beside', 'a', 'boat', 'under', 'a', 'bridge', '.', '<eos>']\n",
            "[Epoch 32 / 50]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['a', 'horse', 'is', 'walking', 'beside', 'a', 'boat', 'under', 'a', 'bridge', '.', '<eos>']\n",
            "[Epoch 33 / 50]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['a', 'horse', 'is', 'walking', 'beside', 'a', 'boat', 'under', 'a', 'bridge', '.', '<eos>']\n",
            "[Epoch 34 / 50]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['a', 'horse', 'is', 'walking', 'beside', 'a', 'boat', 'under', 'a', 'bridge', '.', '<eos>']\n",
            "[Epoch 35 / 50]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['a', 'horse', 'is', 'walking', 'beside', 'a', 'boat', 'under', 'a', 'bridge', '.', '<eos>']\n",
            "[Epoch 36 / 50]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['a', 'horse', 'is', 'walking', 'under', 'a', 'boat', 'near', 'a', 'boat', '.', '<eos>']\n",
            "[Epoch 37 / 50]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['a', 'horse', 'is', 'walking', 'beside', 'a', 'boat', 'under', 'a', 'bridge', '.', '<eos>']\n",
            "[Epoch 38 / 50]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['a', 'horse', 'is', 'walking', 'beside', 'a', 'boat', 'under', 'a', 'bridge', '.', '<eos>']\n",
            "[Epoch 39 / 50]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['a', 'horse', 'is', 'walking', 'beside', 'a', 'boat', 'under', 'a', 'bridge', '.', '<eos>']\n",
            "[Epoch 40 / 50]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['a', 'horse', 'is', 'walking', 'beside', 'a', 'boat', 'under', 'a', 'bridge', '.', '<eos>']\n",
            "[Epoch 41 / 50]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['a', 'horse', 'is', 'walking', 'beside', 'a', 'boat', 'under', 'a', 'bridge', '.', '<eos>']\n",
            "[Epoch 42 / 50]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['a', 'horse', 'is', 'walking', 'beside', 'a', 'boat', 'under', 'a', 'bridge', '.', '<eos>']\n",
            "[Epoch 43 / 50]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['a', 'horse', 'is', 'walking', 'beside', 'a', 'boat', 'under', 'a', 'bridge', '.', '<eos>']\n",
            "[Epoch 44 / 50]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['a', 'horse', 'is', 'walking', 'beside', 'a', 'boat', 'under', 'a', 'bridge', '.', '<eos>']\n",
            "[Epoch 45 / 50]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['a', 'horse', 'is', 'walking', 'beside', 'a', 'boat', 'under', 'a', 'bridge', '.', '<eos>']\n",
            "[Epoch 46 / 50]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['a', 'horse', 'is', 'walking', 'beside', 'a', 'boat', 'under', 'a', 'bridge', '.', '<eos>']\n",
            "[Epoch 47 / 50]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['a', 'horse', 'is', 'walking', 'beside', 'a', 'boat', 'under', 'a', 'bridge', '.', '<eos>']\n",
            "[Epoch 48 / 50]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['a', 'horse', 'is', 'walking', 'beside', 'a', 'boat', 'under', 'a', 'bridge', '.', '<eos>']\n",
            "[Epoch 49 / 50]\n",
            "=> Saving checkpoint\n",
            "Translated example sentence: \n",
            " ['a', 'horse', 'is', 'walking', 'beside', 'a', 'boat', 'under', 'a', 'bridge', '.', '<eos>']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation & BLEU Score"
      ],
      "metadata": {
        "id": "Mkkgq5lSShII"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# running on entire test data takes a while\n",
        "score = bleu(test_data[1:100], model, german, english, device)\n",
        "print(f\"Bleu score {score * 100:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OfQgA9a6IUzi",
        "outputId": "ad8b2c90-33db-4227-f2f6-bcacf1b37f2e"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bleu score 28.90\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tDjNZlzLaXrp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}